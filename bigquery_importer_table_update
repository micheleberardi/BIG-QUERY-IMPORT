#!/usr/bin/env python3.4
# -*- coding: utf-8 -*-

__author__ = "Michele Berardi"
__copyright__ = "Copyright 2018, "
__license__ = "GPL"
__version__ = "1.0.1"
__maintainer__ = "Michele Berardi"
__email__ = "michele@berardi.com"
__status__ = "Production"

import json
import logging
import os
import time
from datetime import datetime
import ndjson
import pymysql
from dateutil.relativedelta import relativedelta
from googleadwords.googleapi.bigquery.google.cloud import bigquery


# FUNCTION QUERY MYSQL
def query():
    cursor.execute(
        "select insert_date, date, account_id, account_name, account_time_zone_id, account_time_zone_name, account_time_zone_offset_hours_utc, hourly_stats_aggregated_by_advertiser_time_zone, campaign_id, campaign_name, adset_id, adset_name, ads_id, ads_name, clicks, impressions, frequency, unique_clicks, spend,cost_per_inline_link_click ,inline_link_clicks,reach, objective, cpc, cpm, cpp, ctr, conversions, source,md5string FROM db_ads.ads_manager_unique where date between '" + date_start + "' and '" + date_start + "'")
    row_headers = [x[0] for x in cursor.description]  # this will extract row headers
    data = cursor.fetchall()
    json_data = []
    for result in data:
        json_data.append(dict(zip(row_headers, result)))
    return json.dumps(json_data, indent=4, sort_keys=False, default=str, *'')


if __name__ == '__main__':
    # SECTION PARAMETERS
    os.environ[
        "GOOGLE_APPLICATION_CREDENTIALS"] = "/google-123445.json"

    # TIME NOW
    datenow = datetime.now().strftime('%Y-%m-%d')
    date2 = datetime.today() + relativedelta(days=0)
    date3 = datetime.today() + relativedelta(days=0)
    date_start = date2.strftime('%Y-%m-%d')
    date_end = date3.strftime('%Y-%m-%d')
    date_query = date2.strftime('%Y%m%d')
    print("START DATE ", date_start)
    print("END DATE ", date_end)

    # START TIME
    start = time.time()

    # SECTION LOG
    try:
        logging.basicConfig(level=logging.DEBUG,
                            format='%(asctime)s %(levelname)-8s %(message)s',
                            datefmt='%a, %d %b %Y %H:%M:%S',
                            filename='/var/www/html/source/ads_manager/logs/app.log', filemode='a')
    except:
        logging.basicConfig(level=logging.DEBUG,
                            format='%(asctime)s %(levelname)-8s %(message)s',
                            datefmt='%a, %d %b %Y %H:%M:%S',
                            filename='logs/app.log', filemode='a')
    logging.debug('>>>>> START TRANSACTION <<<<<')

    # SECTION DATABASE MYSQL
    mydb = pymysql.connect(host='10.XX.XX.XX', user='michelone', passwd='xxxxxx', db='db_ads', use_unicode=True,
                           charset="utf8")
    cursor = mydb.cursor()
    logging.debug('>>>>> check the database')

    # QUERY MYSQL
    result1 = query()
    
    # PARSE JSON FROM MYSQL FUNCTION
    data = json.loads(result1)
    str = json.dumps(data)
    parsed = json.loads(str)
    with open('data.json', 'w') as f:
        ndjson.dump(parsed, f)
        
    # IMPORT INTO BIG QUERY
    filename = 'data.json'
    client = bigquery.Client(project="bigquery-rtb")
    dataset_id = 'adwords'
    table_id = 'ads_manager'
    dataset_ref = client.dataset(dataset_id)
    table_ref = dataset_ref.table(table_id + "$" + date_query)
    
    # ACTION INTO BIG QUERY
    job_config = bigquery.LoadJobConfig()
    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE.partition(date_query)
    job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON
    with open(filename, "rb") as source_file:
        job = client.load_table_from_file(source_file, table_ref, job_config=job_config)
    job.result()  # Waits for table load to complete.
    print("Loaded {} rows into {}:{}.".format(job.output_rows, dataset_id, table_id + "$" + date_start))
